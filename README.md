# Unified Framework for Diffusion Models 

A **unified PyTorch framework** for training, evaluating, and comparing modern diffusionâ€‘based generative models â€“ including **DDPM**, **DDIM**, and **LDM** â€“ with both unconditional and conditional variants.

> This repository accompanies my masterâ€™s capstone thesis â€œ\**Unified Framework for Diffusion Models with Comparative Analysis and Evaluation**.â€ It consolidates research code, reproducible experiments, and utilities into a single, easyâ€‘toâ€‘extend codebase.

<br>

## Features

| Category         | Highlights                                                                                                                                                                           |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Model Zoo**    | â€¢ DDPMÂ & DDIM (based on `lucidrains/denoisingâ€‘diffusionâ€‘pytorch`)â€¢ Latent Diffusion (ported & simplified from `CompVis/latentâ€‘diffusion`)â€¢ Plugâ€‘andâ€‘play Uâ€‘Net backbones (2D/latent) |
| **Conditioning** | â€¢Â Unconditional generationâ€¢Â Imageâ€‘toâ€‘Image (edge âœ image, etc.)â€¢Â Textâ€‘toâ€‘Image withÂ Â â€¢Â *embedding concatenation*Â Â â€¢Â *multiâ€‘scale crossâ€‘attention*                                    |                                                                                                                                                                     
| **Evaluation**   | Builtâ€‘in FID & IS computation, sample grids, TensorBoard support.                                                                                                                    |
| **Performance**  | Mixedâ€‘precision, gradient accumulation, multiâ€‘GPU viaÂ ğŸ¤— `accelerate`.                                                                                                               |

<br>


## GettingÂ Started

### 1.Â CloneÂ 

```bash
git clone https://github.com/lbarseghyan/diffusion-models.git
cd diffusion-models
```

### 2.Â CreateÂ Environment

```bash
# Linux /Â CUDAâ€‘enabled
conda env create -f environment.yml
conda activate diff

# macOS (CPU) 
conda env create -f environment_macos.yml
conda activate diff
```

<br>

## QuickÂ Examples

### TrainÂ DDPMÂ onÂ CIFARâ€‘10

```bash
python denoising-diffusion-pytorch/train/train_ddpm.py \
    --config=denoising-diffusion-pytorch/train/configs/ddpm_cifar.yaml
```


### Train LDMÂ (edge âœ shoe)

```bash
python latent-diffusion/train/train_ldm_image_conditional.py \
    --config=latent-diffusion/train/configs/ddpm_image_conditional_edges2shoes.yaml
```
<br>

## Contributing
Pull requests are welcome! Please open an issue first to discuss major changes.


## Citation
If you use this codebase, please cite the thesis:

```bibtex
@mastersthesis{Barseghyan2025Diffusion,
  author       = {Barseghyan, Laura},
  title        = {Unified Framework for Diffusion Models with Comparative Analysis and Evaluation},
  school       = {American University of Armenia},
  year         = {2025},
  url          = {https://github.com/lbarseghyan/diffusion-models}
}
```

<br>

This repository also incorporates code from:

* `lucidrains/denoising-diffusion-pytorch`&#x20;
* `CompVis/latent-diffusion`&#x20;


## Acknowledgements
Huge thanks to Phil Wang (`lucidrains`) and the CompVis team for openâ€‘sourcing their pioneering diffusion model implementations.
